{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide Content Section - Part A: Predictive Analytics with Neural Networks\n",
    "\n",
    "**Title: Decoding Market Dynamics: Neural Networks in Predictive Analytics**\n",
    "\n",
    "- **Data-driven Predictions**\n",
    "  - Utilizes historical sales, price, and advertising data.\n",
    "  - Illustrates non-linear relationships and complex patterns.\n",
    "\n",
    "- **Scenario: Pricing and Advertising**\n",
    "  - Case study: Product sales influenced by price and advertising spend.\n",
    "  - Identifies the threshold where price affects the impact of advertising.\n",
    "\n",
    "### Lab Content Section - Part B1: MS Excel Neural Network Modeling\n",
    "\n",
    "1. **Prepare Data**: Open \"Neuralpriceads.xlsx\". Use the 'Data' worksheet containing sales, price, and advertising data (C3:E335).\n",
    "   \n",
    "2. **Run Regression**: In Excel, use the 'Data Analysis' tool to perform regression analysis. Input Y Range as Sales (C4:C335) and X Range as Price and Advertising (D4:E335). Output on a new 'Regression' worksheet.\n",
    "\n",
    "3. **Launch NeuralTools**: Access NeuralTools from the Palisade Decision Tools in the Start Menu.\n",
    "\n",
    "4. **Select Data for Analysis**: In Excel, select the data range C3:E335 for analysis.\n",
    "\n",
    "5. **Configure Data Set**: Use the Data Set Manager in NeuralTools to designate data as dependent and independent. Set Sales as dependent and Price and Advertising as independent.\n",
    "\n",
    "6. **Train Neural Network**: In NeuralTools, go to 'Train' and set parameters as shown in the training dialog box. Randomly select 20% for testing to prevent overfitting.\n",
    "\n",
    "7. **Interpret Results**: Examine the summary report for mean absolute error and RMSE, comparing it with the regression's standard error.\n",
    "\n",
    "8. **Predict New Data**: Use the 'Predict' function in NeuralTools for new Price and Advertising data. The predicted sales will reflect the learned patterns.\n",
    "\n",
    "### Lab Content Section - Part B2: Python + SQLite3 Neural Network Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = pd.read_excel('/mnt/data/Neuralpriceads.xlsx', sheet_name='Data', usecols='C:E')\n",
    "\n",
    "# Prepare dataset\n",
    "X = data[['Price', 'Advertising']]\n",
    "y = data['Sales']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train neural network\n",
    "nn = MLPRegressor(hidden_layer_sizes=(100,), random_state=42)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = nn.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Predict new data points\n",
    "new_data = pd.DataFrame({'Price': [7, 9], 'Advertising': [60, 50]})\n",
    "new_predictions = nn.predict(new_data)\n",
    "print(f\"Predictions for new data: {new_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide Content Section - Part A: Neural Networks in Forecasting Airline Miles\n",
    "\n",
    "**Title: Navigating the Skies: Forecasting with Neural Networks**\n",
    "\n",
    "- **Forecasting Airline Miles**\n",
    "  - Compares neural network forecasts to traditional methods.\n",
    "  - Demonstrates superior accuracy in predicting future trends.\n",
    "\n",
    "- **Scenario: Airline Industry**\n",
    "  - Example: Using past 12 months of airline miles data to predict future demand.\n",
    "  - Highlights neural networks' ability to reduce forecast error significantly.\n",
    "\n",
    "### Lab Content Section - Part B1: M.S. Excel Neural Network Forecasting\n",
    "\n",
    "1. **Open Workbook**: Load \"neuralnetsairlinemiles.xlsx\" and select the dataset.\n",
    "\n",
    "2. **Run Linear Regression**: Use Excel's Analysis ToolPak to regress Column C (Current Airline Miles) against Columns D-O (Past Airline Miles).\n",
    "\n",
    "   - Result: MAD of 961,855 in regression worksheet.\n",
    "   \n",
    "3. **Set Up NeuralTools**: Initialize NeuralTools add-in from the Palisade Decision Tools suite.\n",
    "\n",
    "4. **Configure Data Analysis**: In the Data Set Manager, define Column C as the dependent variable and Columns D-O as independent variables.\n",
    "\n",
    "5. **Train Neural Network**: Use the 'Train' function in NeuralTools, setting aside 20% of data for validation to prevent overfitting.\n",
    "\n",
    "6. **Evaluate Neural Network**: Check the MAD in the NeuralTools summary report.\n",
    "\n",
    "   - Result: MAD of 497,000, indicating enhanced accuracy over linear regression.\n",
    "   \n",
    "7. **Apply Predictions**: Use the 'Predict' function to forecast future airline miles based on new data inputs.\n",
    "\n",
    "### Lab Content Section - Part B2: Python+SQLite3 Forecasting Airline Miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load data\n",
    "data = pd.read_excel('/mnt/data/neuralnetsairlinemiles.xlsx', sheet_name='Data')\n",
    "\n",
    "# Prepare dataset\n",
    "X = data.iloc[:, 1:13]  # Assuming D-O columns are indexed 1-12\n",
    "y = data['CurrentMiles']  # Assuming 'CurrentMiles' is the column name for Column C\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize neural network\n",
    "nn_model = MLPRegressor(random_state=0)\n",
    "\n",
    "# Train the model\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nn_predictions = nn_model.predict(X_test)\n",
    "\n",
    "# Calculate MAD\n",
    "mad = np.mean(np.abs(y_test - nn_predictions))\n",
    "print(f\"Mean Absolute Deviation: {mad}\")\n",
    "\n",
    "# Forecast future airline miles\n",
    "# Replace 'future_data' with actual new data for prediction\n",
    "future_data = np.array([[...]])  # placeholder for new data\n",
    "future_predictions = nn_model.predict(future_data)\n",
    "print(f\"Future Predictions: {future_predictions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide Content Section - Part A: Simplifying Complexity with PCA\n",
    "\n",
    "**Title: Simplifying Market Complexity: Principal Components Analysis**\n",
    "\n",
    "- **Concept of PCA**\n",
    "  - PCA transforms a large set of variables into a smaller one that still contains most of the information.\n",
    "  \n",
    "- **Scenario: Market Segmentation**\n",
    "  - Marketers use PCA to identify key factors affecting consumer preferences from extensive survey data.\n",
    "\n",
    "### Lab Content Section - Part B1: MS Excel PCA Implementation\n",
    "\n",
    "- **Data Preparation**: Open the dataset in MS Excel.\n",
    "  \n",
    "- **Standardization**: Standardize the variables to have a mean of 0 and standard deviation of 1.\n",
    "\n",
    "- **Correlation Matrix**: Calculate the correlation matrix for the standardized data.\n",
    "\n",
    "- **Eigenvalues and Eigenvectors**: Use Excel's 'Analysis ToolPak' to perform eigenvalue decomposition.\n",
    "\n",
    "- **Principal Component Scores**: Compute the principal component scores for the data points.\n",
    "\n",
    "- **Interpretation**: Analyze the loadings of the principal components to understand the variables' impact.\n",
    "\n",
    "### Lab Content Section - Part B2: Python PCA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and standardize the data\n",
    "df = pd.read_excel('/mnt/data/Dataset.xlsx')  # Replace with your file path and sheet name\n",
    "features = df.columns[1:]  # Assuming the first column is an identifier\n",
    "x = df.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)  # Adjust based on desired number of components\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f'Explained Variance: {explained_variance}')\n",
    "\n",
    "# Identify significant principal components based on explained variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
