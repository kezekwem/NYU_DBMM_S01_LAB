{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Clustering in Marketing: Unveiling Patterns in Urban Demographics\n",
    "\n",
    "#### Part A - Slide Contents and Brief Discussion:\n",
    "- **Clustering U.S. Cities for Marketing Insights**\n",
    "  - **Concept**: Cluster analysis groups cities based on demographic similarities to unveil patterns useful in marketing research, advertising, and sales strategies.\n",
    "  - **Application**: By identifying demographically similar clusters, marketers can tailor advertising campaigns and product offerings to meet the specific needs of each group.\n",
    "  - **Real-World Example**: Suppose a company aims to launch a new product in U.S. cities. Using cluster analysis, they discover four distinct demographic clusters. For Atlanta, with a high percentage of Black population, a different marketing approach is applied compared to a city with a higher Hispanic or Asian demographic. This targeted strategy ensures more effective advertising and better market penetration.\n",
    "\n",
    "#### Part B1 - MS Excel Practice/Exercise/Steps:\n",
    "- **Excel File**: `cluster.xlsx`\n",
    "- **Steps for Standardizing Demographic Attributes**:\n",
    "  1. Open `cluster.xlsx` and navigate to the sheet with demographic data.\n",
    "  2. To compute the mean for the Black percentage, enter `=AVERAGE(C10:C58)` in cell C1.\n",
    "  3. For the standard deviation of Black percentages, use `=STDEV(C10:C58)` in cell C2.\n",
    "  4. Copy these formulas across D1:G2 to calculate the mean and standard deviation for each demographic attribute.\n",
    "  5. In cell I10, calculate the standardized percentage of Blacks for Albuquerque by using `=STANDARDIZE(C10, C$1, C$2)`.\n",
    "  6. Extend this formula from I10 to N58 to compute z-scores for all cities and attributes.\n",
    "- **Troubleshooting Tips**:\n",
    "  - Ensure formulas are correctly copied to reflect each attribute's specific column references.\n",
    "  - Verify the mean and standard deviation calculations by comparing with manual computations for accuracy.\n",
    "\n",
    "#### Part B2 - Python+SQLite3 Practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load data from Excel with headers included\n",
    "data = pd.read_excel('data/cluster.xlsx', sheet_name='cluster', usecols='C:G', skiprows=8, nrows=50)\n",
    "\n",
    "# Standardize attributes and replace spaces with underscores in column names\n",
    "data.columns = [column.replace(\" \", \"_\") for column in data.columns]\n",
    "for column in data.columns:\n",
    "    data[column] = (data[column] - data[column].mean()) / data[column].std()\n",
    "\n",
    "# Save to SQLite3 database with modified column names\n",
    "conn = sqlite3.connect('data/cluster.db')\n",
    "data.to_sql('cities', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Function to print DataFrame in a more readable, table-like format\n",
    "def print_dataframe_sqlite(query, connection):\n",
    "    df = pd.read_sql(query, connection)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "# Display the table structure\n",
    "print(\"Table Structure:\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT sql FROM sqlite_master WHERE tbl_name = 'cities' AND type = 'table'\")\n",
    "print(cursor.fetchone()[0])\n",
    "\n",
    "# Example SQL Query: Load and display data in a readable format\n",
    "print(\"\\nExample Data Query:\")\n",
    "print_dataframe_sqlite(\"SELECT * FROM cities LIMIT 5\", conn)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Harnessing Clustering for Strategic Marketing Insights\n",
    "\n",
    "#### Part A - Slide Contents and Brief Discussion:\n",
    "- **Understanding Clustering for Market Segmentation**\n",
    "  - **Concept Overview**: Clustering allows marketers to group cities or consumers based on demographic similarities or preferences, facilitating targeted marketing strategies.\n",
    "  - **Application in Marketing**: Identifying clusters helps in tailoring marketing campaigns, product development, and distribution strategies to meet the specific needs of different segments.\n",
    "  - **Real-World Example**: Analyzing moviegoers' ratings for \"Fight Club\" and \"Sea Biscuit\" to segment audiences into four distinct preferences groups enables a movie distribution company to customize promotional activities, enhancing audience engagement and maximizing box office returns.\n",
    "\n",
    "#### Part B1 - MS Excel Practice/Exercise/Steps:\n",
    "- **Excel File**: `Clustermotivation.xlsx`\n",
    "- **Steps for Cluster Analysis**:\n",
    "  1. **Setup Trial Anchors**: In cells H5:H8, input trial values (1-4) representing initial cluster anchors.\n",
    "  2. **Lookup Cluster Anchors' Names**: Use `=VLOOKUP(H5, A9:N58, 2, FALSE)` in G5 and copy through G8 to identify each cluster center candidate by name.\n",
    "  3. **Identify Z-Scores for Anchors**: In I5:N8, apply `=VLOOKUP($H5, A9:N58, COLUMN()-6, FALSE)` to find z-scores for each cluster anchor, adjusting COLUMN() as necessary for your setup.\n",
    "  4. **Compute Squared Distances**: Use `=SUMXMY2($I$5:$N$5, $I10:$N10)` in O10 to calculate the squared distance from Albuquerque to the first cluster anchor. Adjust cell references for subsequent anchors and copy from O10:R10 down to O58:R58.\n",
    "  5. **Find Minimum Distance**: Enter `=MIN(O10:R10)` in S10 and copy down to S58 to determine the closest cluster anchor for each city.\n",
    "  6. **Sum of Squared Distances**: Calculate the total squared distance with `=SUM(S10:S58)` in S8.\n",
    "  7. **Assign Clusters**: In T10, use `=MATCH(S10, O10:R10, 0)` and copy down to T58 to identify the cluster assignment for each city.\n",
    "- **Troubleshooting Tips**:\n",
    "  - Ensure correct cell references and formulas are copied accurately.\n",
    "  - Verify that the Solver settings are correctly configured for the Evolutionary Solver with a 0.5 Mutation rate for optimal performance.\n",
    "\n",
    "#### Part B2 - Python+SQLite3 Practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('data/Clustermotivation.xlsx', sheet_name='Sheet1', skiprows=8, nrows=49, usecols='C:G')\n",
    "data.columns = [c.replace(\" \", \"_\") for c in data.columns]\n",
    "\n",
    "# Standardize the data\n",
    "z_scores = (data - data.mean()) / data.std()\n",
    "\n",
    "# Save standardized data to SQLite\n",
    "conn = sqlite3.connect('data/clustering.db')\n",
    "z_scores.to_sql('cities', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Define a function to calculate squared distances and assign clusters\n",
    "def assign_clusters(conn, trial_anchors):\n",
    "    cursor = conn.cursor()\n",
    "    query = \"SELECT * FROM cities\"\n",
    "    cities = pd.read_sql(query, conn)\n",
    "    anchors = cities.iloc[trial_anchors]\n",
    "    distances = cdist(cities, anchors, 'sqeuclidean')\n",
    "    closest_anchor = np.argmin(distances, axis=1) + 1\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "    return closest_anchor, min_distances\n",
    "\n",
    "# Example: Assigning clusters with trial anchors\n",
    "trial_anchors = [0, 1, 2, 3]  # Example anchor indices\n",
    "closest_anchor, min_distances = assign_clusters(conn, trial_anchors)\n",
    "print(\"Assigned Clusters:\", closest_anchor)\n",
    "print(\"Minimum Distances:\", min_distances)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B1 - MS Excel Practice/Exercise/Steps:\n",
    "- Step-by-Step Guide for Conjoint Analysis in Excel\n",
    "1. Open the `CokePepsi.xlsx` file and navigate to the 'Conjoint Data' worksheet.\n",
    "2. For each customer (rows AC29:AW160), run a regression using the LINEST function:\n",
    "- Select a range with five rows and the number of product attributes + 1 column.\n",
    "- Enter `=LINEST(J6:J25, K6:M25, TRUE, TRUE)` in the first cell of the selected range.\n",
    "- Press Control+Shift+Enter to apply the array formula.\n",
    "3. Create a one-way data table for customer numbers (AY11:AY130):\n",
    "- Enter customer numbers in AY11:AY130.\n",
    "- Copy `=R12` into AZ10 and extend to BA10:BB10.\n",
    "- Select the range AY10:BB130, go to Data > What-If Analysis > Data Table, and set $J$3 as the column input cell.\n",
    "4. Copy the regression results to the 'cluster' worksheet and run a cluster analysis with five clusters.\n",
    "- Use customers 1â€“5 as initial anchors for the clusters.\n",
    "- Troubleshooting Tips:\n",
    "- Ensure the array formula is entered correctly with Control+Shift+Enter.\n",
    "- Verify the cell references match the data ranges in your worksheet.\n",
    "- Check for consistent use of absolute and relative cell references.\n",
    "#### Part B2 - Python+SQLite3 Practice:\n",
    "```python\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('data/CokePepsi.xlsx', sheet_name='Conjoint Data', usecols='AC29:AW160')\n",
    "\n",
    "# Connect to SQLite3 database\n",
    "conn = sqlite3.connect('CokePepsi.db')\n",
    "data.to_sql('conjoint_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Function to run regression for each customer and return coefficients\n",
    "def run_regressions(data):\n",
    "    coefficients = []\n",
    "    for index, row in data.iterrows():\n",
    "        # Assuming the independent variables are in the first three columns\n",
    "        X = row.iloc[:3].values.reshape(-1, 3)\n",
    "        y = row.iloc[3]\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        coefficients.append(model.coef_)\n",
    "    return coefficients\n",
    "\n",
    "# Run the regressions and get coefficients\n",
    "coefficients = run_regressions(data)\n",
    "\n",
    "# Perform cluster analysis\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(np.array(coefficients))\n",
    "\n",
    "# Output the cluster results\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Customer {i+1} is in cluster {cluster+1}\")\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "```\n",
    "- Comments:\n",
    "- The code loads the Excel data into a pandas DataFrame.\n",
    "- It then creates a SQLite3 database and imports the data.\n",
    "- A function is defined to run linear regressions for each customer.\n",
    "- KMeans clustering is performed on the regression coefficients.\n",
    "- The cluster for each customer is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('data/CokePepsi.xlsx', sheet_name='Conjoint Data', usecols='AC29:AW160')\n",
    "\n",
    "# Connect to SQLite3 database\n",
    "conn = sqlite3.connect('CokePepsi.db')\n",
    "data.to_sql('conjoint_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Function to run regression for each customer and return coefficients\n",
    "def run_regressions(data):\n",
    "    coefficients = []\n",
    "    for index, row in data.iterrows():\n",
    "    # Assuming the independent variables are in the first three columns\n",
    "        X = row.iloc[:3].values.reshape(-1, 3)\n",
    "        y = row.iloc[3]\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        coefficients.append(model.coef_)\n",
    "    return coefficients\n",
    "\n",
    "# Run the regressions and get coefficients\n",
    "coefficients = run_regressions(data)\n",
    "\n",
    "# Perform cluster analysis\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(np.array(coefficients))\n",
    "\n",
    "# Output the cluster results\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Customer {i+1} is in cluster {cluster+1}\")\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategic Insights through Market Basket Analysis\n",
    "\n",
    "#### Part A - Slide Contents and Brief Discussion:\n",
    "- **Title: Leveraging Market Basket Analysis for Enhanced Retail Strategy**\n",
    "  - **Market Basket Analysis Overview**\n",
    "    - Introduction to the concept of analyzing consumer purchase patterns to identify product associations.\n",
    "    - Significance in marketing for optimizing product placement, inventory management, and promotional strategies.\n",
    "  - **Application in Real-World Retail**\n",
    "    - Example: Supermarkets leveraging insights from cereal and banana purchases to optimize product placement, enhancing the likelihood of simultaneous purchases.\n",
    "    - Lift Calculation: Demonstrates how understanding product purchase combinations can inform strategic decisions, like store layout and cross-promotional offers.\n",
    "\n",
    "#### Part B1 - MS Excel Practice/Exercise/Steps:\n",
    "- **Excel File:** `marketbasket.xlsx`\n",
    "- **Creating Named Ranges:**\n",
    "  1. **Total Transactions Calculation:**\n",
    "     - Cell `L7`: Enter `=COUNT(B:B)` to count the number of transactions.\n",
    "  2. **Computing Product Purchase Fractions:**\n",
    "     - Cells `L9 to L14`: Use `=COUNTIF(INDIRECT(K9),1)/$L$7` to calculate the fraction of transactions involving each product. Replace `K9` with the appropriate cell references for each product.\n",
    "  3. **Day of the Week Transactions Fraction:**\n",
    "     - Cells `L17 to L23`: Apply `=COUNTIF(day_week, K17)/COUNT(day_week)` for each day, adjusting `K17` accordingly to compute the daily transaction fractions.\n",
    "- **Troubleshooting Tips:**\n",
    "  - Ensure named ranges are correctly defined for seamless formula copying.\n",
    "  - Verify cell references and formulas for accuracy in calculations.\n",
    "\n",
    "#### Part B2 - Python+SQLite3 Practice:\n",
    "```python\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('marketbasket.xlsx', sheet_name='data', usecols='B:H', skiprows=8)\n",
    "\n",
    "# Creating the SQLite3 database from the loaded Excel file\n",
    "conn = sqlite3.connect('marketbasket.db')\n",
    "data.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Python code to calculate total transactions\n",
    "total_transactions = pd.read_sql_query('SELECT COUNT(*) as total FROM transactions', conn)\n",
    "\n",
    "# Computing fractions of transactions involving each product\n",
    "products = ['vegetables', 'meat', 'milk']  # Example product list\n",
    "for product in products:\n",
    "    query = f'''\n",
    "    SELECT COUNT(*) * 1.0 / (SELECT COUNT(*) FROM transactions) as fraction\n",
    "    FROM transactions\n",
    "    WHERE \"{product}\" = 1\n",
    "    '''\n",
    "    fraction = pd.read_sql_query(query, conn)\n",
    "    print(f'Fraction of transactions involving {product}:', fraction['fraction'][0])\n",
    "\n",
    "# Calculating day of the week transaction fractions\n",
    "days = range(1, 8)  # 1=Monday, 7=Sunday\n",
    "for day in days:\n",
    "    day_query = f'''\n",
    "    SELECT COUNT(*) * 1.0 / (SELECT COUNT(*) FROM transactions) as fraction\n",
    "    FROM transactions\n",
    "    WHERE day_week = {day}\n",
    "    '''\n",
    "    day_fraction = pd.read_sql_query(day_query, conn)\n",
    "    print(f'Fraction of transactions on day {day}:', day_fraction['fraction'][0])\n",
    "\n",
    "# Example of calculating lift for meat and vegetables\n",
    "lift_query = '''\n",
    "SELECT (SELECT COUNT(*) FROM transactions WHERE meat = 1 AND vegetables = 1) * 1.0 /\n",
    "       ((SELECT COUNT(*) FROM transactions) * \n",
    "       (SELECT COUNT(*) FROM transactions WHERE meat = 1) / (SELECT COUNT(*) FROM transactions) *\n",
    "       (SELECT COUNT(*) FROM transactions WHERE vegetables = 1) / (SELECT COUNT(*) FROM transactions)) AS lift\n",
    "'''\n",
    "lift = pd.read_sql_query(lift_query, conn)\n",
    "print('Lift for meat and vegetables:', lift['lift'][0])\n",
    "```\n",
    "- **Explanation:** This Python script demonstrates the process of loading data from an Excel file into a SQLite3 database, then computing the total number of transactions, fractions of transactions involving specific products, day of the week transaction fractions, and calculating lift for product combinations using SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('marketbasket.xlsx', sheet_name='data', usecols='B:H', skiprows=8)\n",
    "\n",
    "# Creating the SQLite3 database from the loaded Excel file\n",
    "conn = sqlite3.connect('marketbasket.db')\n",
    "data.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Python code to calculate total transactions\n",
    "total_transactions = pd.read_sql_query('SELECT COUNT(*) as total FROM transactions', conn)\n",
    "\n",
    "# Computing fractions of transactions involving each product\n",
    "products = ['vegetables', 'meat', 'milk']  # Example product list\n",
    "for product in products:\n",
    "    query = f'''\n",
    "    SELECT COUNT(*) * 1.0 / (SELECT COUNT(*) FROM transactions) as fraction\n",
    "    FROM transactions\n",
    "    WHERE \"{product}\" = 1\n",
    "    '''\n",
    "    fraction = pd.read_sql_query(query, conn)\n",
    "    print(f'Fraction of transactions involving {product}:', fraction['fraction'][0])\n",
    "\n",
    "# Calculating day of the week transaction fractions\n",
    "days = range(1, 8)  # 1=Monday, 7=Sunday\n",
    "for day in days:\n",
    "    day_query = f'''\n",
    "    SELECT COUNT(*) * 1.0 / (SELECT COUNT(*) FROM transactions) as fraction\n",
    "    FROM transactions\n",
    "    WHERE day_week = {day}\n",
    "    '''\n",
    "    day_fraction = pd.read_sql_query(day_query, conn)\n",
    "    print(f'Fraction of transactions on day {day}:', day_fraction['fraction'][0])\n",
    "\n",
    "# Example of calculating lift for meat and vegetables\n",
    "lift_query = '''\n",
    "SELECT (SELECT COUNT(*) FROM transactions WHERE meat = 1 AND vegetables = 1) * 1.0 /\n",
    "       ((SELECT COUNT(*) FROM transactions) * \n",
    "       (SELECT COUNT(*) FROM transactions WHERE meat = 1) / (SELECT COUNT(*) FROM transactions) *\n",
    "       (SELECT COUNT(*) FROM transactions WHERE vegetables = 1) / (SELECT COUNT(*) FROM transactions)) AS lift\n",
    "'''\n",
    "lift = pd.read_sql_query(lift_query, conn)\n",
    "print('Lift for meat and vegetables:', lift['lift'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Market Basket Analysis: Triadic Lifts and Marketing Implications\n",
    "\n",
    "#### Part A - Slide Contents and Brief Discussion:\n",
    "- **Title: Enhancing Marketing Strategy with Triadic Lift Analysis**\n",
    "  - **Exploring Triadic Lift Analysis**\n",
    "    - Introduction to the concept of calculating the lift for three attributes, such as two product categories and a day of the week, to uncover deeper insights into customer purchasing patterns.\n",
    "    - Application in marketing for identifying specific days and product combinations that significantly affect purchasing behavior, aiding in targeted promotions and inventory management.\n",
    "  - **Real-World Application Scenario**\n",
    "    - Example: Analyzing the lift for purchasing baby goods and DVDs on Thursdays helps retailers understand specific customer behaviors, enabling them to tailor promotions, such as special Thursday discounts on baby goods when bought with DVDs, to drive sales.\n",
    "\n",
    "#### Part B1 - MS Excel Practice/Exercise/Steps:\n",
    "- **Excel File:** `marketbasketoptimize.xls`\n",
    "- **Calculating Three-Way Lifts:**\n",
    "  1. **Actual Transactions Calculation:**\n",
    "     - Cell `Q14`: Use array formula `=SUM((INDIRECT(P13)=$P$14)*(INDIRECT(N13)=1)*(INDIRECT(O13)=1))` to compute actual transactions for chosen combinations (e.g., baby goods and vegetables on Friday).\n",
    "  2. **Predicted Transactions Calculation:**\n",
    "     - Cell `R14`: Formula `=IF(N13<>O13, VLOOKUP(N13, K9:L14,2, FALSE)*L7*VLOOKUP(O13, K9:L14,2, FALSE)*VLOOKUP(P14, K17:L23,2),0)` calculates predicted transactions assuming independence between the variables.\n",
    "  3. **Lift Computation:**\n",
    "     - Cell `S14`: Compute lift with `=IF(R14=0,1,Q14/R14)`, indicating how much more (or less) frequently the selected combination occurs compared to what would be expected if they were independent.\n",
    "  4. **Optimizing the Three-Way Lift**\n",
    "     - In an actual situation with many products, there would be a huge number of threewaylifts. For example, with 1,000 products, you can expect 1,0003 = 1 billion threeway lifts! Despite this, a retailer is often interested in fi nding the largest three-way lifts. Intelligent use of the Evolutionary Solver can ease this task. To illustrate the basic idea, you can use the Evolutionary Solver to determine the combination of products and day of the week with maximum lift.\n",
    "        1. Use Evolutionary Solver with the changing cells being the day of the week (cell P14) and an index refl ecting the product classes (cells N12 and O12). Cells N12 and O12 are linked with lookup tables to cells N13:O13. For instance, a 1 in cell N12 makes N13 be vegetables. Figure 29-4 shows the Evolutionary Solver window.\n",
    "        2. Maximize lift (S14), and then choose N12 and O12 (product classes) to be\n",
    "        integers between 1 and 6. P14 is an integer between 1 and 7.\n",
    "        3. Add a constraint that Q14 >= 20 to ensure you count only combinations that\n",
    "        occur a reasonable number of times.\n",
    "        4. Set the Mutation Rate to .5.\n",
    "        You can find the maximum lift combination, as shown in Figure 29-5.\n",
    "\n",
    "The three-way lift, as shown in Figure 29-5, indicates that roughly 6.32 times more people, as expected under an independence assumption, buy DVDs and baby goods on Thursday. This indicates that on Thursdays placing DVDs (often an impulse purchase) in the baby sections will increase profits.\n",
    "\n",
    "- **Troubleshooting Tips:**\n",
    "  - Ensure correct use of array formulas and verify cell references.\n",
    "  - Check for correct implementation of INDIRECT functions for dynamic data referencing.\n",
    "\n",
    "#### Part B2 - Python+SQLite3 Practice:\n",
    "- **Explanation:** This Python script demonstrates how to perform a three-way lift analysis using a SQLite database, providing insights into the complex interplay between product purchases and specific days of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "data = pd.read_excel('marketbasketoptimize.xls', sheet_name='Initial')  # Assume correct sheet name\n",
    "\n",
    "# Convert DataFrame to SQLite database\n",
    "conn = sqlite3.connect('marketbasketoptimize.db')\n",
    "data.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Function to calculate three-way lift\n",
    "def calculate_three_way_lift(product1, product2, day):\n",
    "    total_transactions = pd.read_sql_query(\"SELECT COUNT(*) as count FROM transactions\", conn).iloc[0]['count']\n",
    "    transactions_day = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM transactions WHERE day_week = {day}\", conn).iloc[0]['count']\n",
    "    product1_count = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM transactions WHERE {product1} = 1\", conn).iloc[0]['count']\n",
    "    product2_count = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM transactions WHERE {product2} = 1\", conn).iloc[0]['count']\n",
    "    both_and_day_count = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM transactions WHERE {product1} = 1 AND {product2} = 1 AND day_week = {day}\", conn).iloc[0]['count']\n",
    "    expected_count = (transactions_day / total_transactions) * (product1_count / total_transactions) * (product2_count / total_transactions) * total_transactions\n",
    "    lift = both_and_day_count / expected_count if expected_count > 0 else 0\n",
    "    return lift\n",
    "\n",
    "# Example calculation\n",
    "lift_veg_baby_thursday = calculate_three_way_lift('vegetables', 'baby', 4)  # Assuming 4 represents Thursday\n",
    "print(f'Lift for Vegetables and Baby Goods on Thursday: {lift_veg_baby_thursday}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
