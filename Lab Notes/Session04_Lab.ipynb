{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Review of Excel Exercise for Clustering U.S. Cities\n",
    "\n",
    "The Excel exercise involves clustering 49 of America's largest cities based on demographic data such as percentage of Black, Hispanic, Asian populations, median age, unemployment rate, and per capita income. The aim is to group cities into four clusters that are demographically similar. The process involves standardizing the demographic attributes to ensure that each attribute contributes equally to the analysis. This is achieved by subtracting the mean and dividing by the standard deviation for each attribute. The Solver tool is used to minimize the sum of squared distances from each city to its nearest cluster center, thereby identifying the optimal clusters.\n",
    "\n",
    "#### Steps in Excel for Clustering:\n",
    "\n",
    "1. **Data Preparation**: The demographic data for each city is listed, including percentages of Black, Hispanic, Asian populations, median age, unemployment rate, and per capita income.\n",
    "\n",
    "2. **Standardization of Attributes**: To ensure each demographic attribute contributes equally, each attribute is standardized. This involves subtracting the mean and dividing by the standard deviation of each attribute across all cities.\n",
    "\n",
    "3. **Choosing Cluster Anchors**: Initial trial anchors are selected to represent the centers of the clusters. The aim is to assign each city to the nearest cluster anchor based on the standardized attributes.\n",
    "\n",
    "4. **Calculating Distances**: For each city, the squared distance to each cluster anchor is calculated using the standardized values.\n",
    "\n",
    "5. **Solver Optimization**: The Solver tool is used to find the set of cluster anchors that minimizes the sum of squared distances of each city from its closest anchor.\n",
    "\n",
    "6. **Analysis and Interpretation**: The resulting clusters are analyzed to understand the demographic similarities within each cluster and differences between clusters. This helps in interpreting the market segments represented by each cluster.\n",
    "\n",
    "### Part B: Python and SQLite Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Structure and Example Data:\n",
      "   Percentage_Black  Percentage_Hispanic  Percentage_Asian  Median_Age  \\\n",
      "0          2.341074            -0.743119         -0.455678   -0.433767   \n",
      "1         -0.709486             0.539525         -0.277852   -1.425234   \n",
      "2          1.897356            -0.804197         -0.455678    0.557700   \n",
      "3          0.067020            -0.193414         -0.100027   -0.929500   \n",
      "4          0.399808            -0.804197         -0.366765    0.061967   \n",
      "\n",
      "   Unemployment_Rate  Per_Capita_Income  \n",
      "0          -0.763686           0.305445  \n",
      "1          -1.504229          -0.592189  \n",
      "2           1.457945           0.305445  \n",
      "3          -0.763686           0.903867  \n",
      "4          -1.504229          -0.292978  \n",
      "Assigned Clusters Example:\n",
      "    Cluster\n",
      "0         1\n",
      "1         3\n",
      "2         4\n",
      "3         3\n",
      "4         3\n",
      "5         4\n",
      "6         1\n",
      "7         4\n",
      "8         3\n",
      "9         4\n",
      "10        2\n",
      "11        1\n",
      "12        3\n",
      "13        3\n",
      "14        4\n",
      "15        4\n",
      "16        2\n",
      "17        3\n",
      "18        3\n",
      "19        3\n",
      "20        3\n",
      "21        3\n",
      "22        2\n",
      "23        1\n",
      "24        2\n",
      "25        3\n",
      "26        3\n",
      "27        3\n",
      "28        1\n",
      "29        4\n",
      "30        4\n",
      "31        3\n",
      "32        3\n",
      "33        4\n",
      "34        3\n",
      "35        3\n",
      "36        3\n",
      "37        3\n",
      "38        4\n",
      "39        3\n",
      "40        3\n",
      "41        2\n",
      "42        2\n",
      "43        2\n",
      "44        3\n",
      "45        3\n",
      "46        3\n",
      "47        3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Update the file path and sheet name according to the provided path\n",
    "file_path = '/Users/kenechukwuezekwem/Library/CloudStorage/OneDrive-Personal/01_NDSU/WORK/NYU SPS IMC/INTG1-GC 1025 _ Database Management & Modeling/Session02/Session02_Lab/data/Session04_LAB_DATA_FirstName LastName_DueDate.xlsx'  # Update this path\n",
    "sheet_name = 'SOLUTIONS_CLUSTER_A'\n",
    "\n",
    "# Load data from the Excel file\n",
    "# Assuming usecols='C:H' captures all the required demographic data\n",
    "data = pd.read_excel(file_path, sheet_name=sheet_name, usecols='C:H', skiprows=9, nrows=50)\n",
    "\n",
    "# Assuming the first row contains headers after skiprows, let's rename the columns directly from the Excel sheet\n",
    "# Replace 'Percentage Black', 'Percentage Hispanic', etc., with the actual column names from your Excel sheet\n",
    "data.columns = ['Percentage_Black', 'Percentage_Hispanic', 'Percentage_Asian', 'Median_Age', 'Unemployment_Rate', 'Per_Capita_Income']\n",
    "\n",
    "# Standardize the data attributes\n",
    "data_standardized = (data - data.mean()) / data.std()\n",
    "\n",
    "# Save standardized data to SQLite database\n",
    "conn = sqlite3.connect('cluster.db')\n",
    "data_standardized.to_sql('us_cities', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Function to print DataFrame in table format\n",
    "def print_df_sqlite(query, conn):\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(df.head())\n",
    "\n",
    "# Display the standardized data table structure and example rows\n",
    "print(\"Table Structure and Example Data:\")\n",
    "print_df_sqlite(\"SELECT * FROM us_cities\", conn)\n",
    "\n",
    "# Define function to assign clusters based on trial anchors\n",
    "def assign_clusters_sqlite(trial_anchors):\n",
    "    # Load standardized data from SQLite\n",
    "    cities = pd.read_sql(\"SELECT * FROM us_cities\", conn)\n",
    "    # Assuming trial_anchors are the indices of the cities selected as initial cluster centers\n",
    "    anchors = cities.iloc[trial_anchors].to_numpy()\n",
    "    # Calculate squared distances using Euclidean metric\n",
    "    distances = cdist(cities, anchors, 'sqeuclidean')\n",
    "    # Assign each city to the closest cluster anchor\n",
    "    cities['Cluster'] = np.argmin(distances, axis=1) + 1\n",
    "    # Save the updated DataFrame with cluster assignments back to SQLite\n",
    "    cities.to_sql('us_cities_clustered', conn, if_exists='replace', index=False)\n",
    "    return cities\n",
    "\n",
    "# Example usage with trial anchors (indices of cities chosen as initial cluster centers)\n",
    "trial_anchors = [0, 10, 20, 30]  # Example indices, replace with actual cluster center indices\n",
    "assigned_clusters = assign_clusters_sqlite(trial_anchors)\n",
    "print(\"Assigned Clusters Example:\")\n",
    "print(assigned_clusters[['Cluster']])\n",
    "\n",
    "# Close the SQLite connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
